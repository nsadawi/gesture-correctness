{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perkeso Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "random_seed = 42\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "#np.random.seed(seed = seed) \n",
    "#import random\n",
    "#random.seed = seed\n",
    "#import os\n",
    "#os.environ['PYTHONHASHSEED'] = '0'\n",
    "#from utils.utilities import *\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plt.style.use('ggplot')\n",
    "#from scipy import stats\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "\n",
    "import augment\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to know how many times we need to generate augmented data for each gesture\n",
    "def aug_times(mov):\n",
    "    a = {'0': 4, '1': 5,'2': 1, '3': 2, '4': 5, '5': 5, '6': 5, '7': 7, '8': 7}\n",
    "    return a[mov]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "patientid_date_label_repetitionNumber_correction_position.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_move_data(mov):\n",
    "    # patientid_date_label_repetitionNumber_correction_position.txt\n",
    "    #moves = ['0']#,'1','2','3','4','5','6','7','8']\n",
    "    labels = ['1','2']\n",
    "    subjects = ['104', '209', '205', '213', '303', '204', '201', '210', '211', '206', '103', '203', '305', '202', '217', '105',\n",
    "     '107',  '304', '302', '212', '102', '306', '208', '214', '307', '106', '216', '215', '218', '207', '301', '101']\n",
    "    #dates = ['19', '14', '12', '13', '07', '18']\n",
    "    #position = ['sit', 'stand','chair','wheelchair','Stand-frame']\n",
    "    data = pd.DataFrame()\n",
    "    #for mov in moves:\n",
    "    #print('Move: ',mov)\n",
    "    for label in labels:\n",
    "        #count = 0\n",
    "        #print('Label: ',label)\n",
    "        for subj in subjects:\n",
    "            #print('Subj: ',subj)\n",
    "            for file_name in glob.glob('/home/noureddin/Perkeso-Simplified/'+subj+'_*_'+mov+'_*_'+label+'_*.txt'):\n",
    "                #count += 1\n",
    "                tmp_df = pd.read_csv(file_name,header=None)\n",
    "                if len(tmp_df) >= 28:\n",
    "                    tmp_ = pd.DataFrame()#for augmentation\n",
    "                    if label == '2':\n",
    "                        #now augment data                        \n",
    "                        augment_times = aug_times(mov)\n",
    "                        for i in range(0,augment_times):                \n",
    "                            tdata = tmp_df.values\n",
    "                            #dd = DA_TimeWarp(DA_Permutation(DA_Rotation(data)))\n",
    "                            dd = augment.DA_TimeWarp3(augment.DA_Rotation((tdata)))\n",
    "                            #make sure the # of rows is 28\n",
    "                            dd = preprocess.normalize_move(pd.DataFrame(dd), 28, mean=False)\n",
    "                            #transform values into specific range\n",
    "                            dd = preprocess.normalize_df(dd) # e.g. all cols in range [0,1]\n",
    "                            #mean centre the df\n",
    "                            dd = preprocess.mean_centre_data(dd)                \n",
    "                            tmp_ = tmp_.append(dd,ignore_index=True)\n",
    "                \n",
    "                    #make sure the # of rows is 28\n",
    "                    tmp_df = preprocess.normalize_move(tmp_df, 28, mean=False)\n",
    "                    #transform values into specific range\n",
    "                    tmp_df = preprocess.normalize_df(tmp_df) # e.g. all cols in range [0,1] \n",
    "                    #mean centre the df\n",
    "                    tmp_df = preprocess.mean_centre_data(tmp_df)\n",
    "                    tmp_df['Original'] = 1 \n",
    "                    if len(tmp_) > 0:\n",
    "                        tmp_['Original']   = 0\n",
    "                        tmp_df = tmp_df.append(tmp_,ignore_index=True)\n",
    "                \n",
    "                    tmp_df.columns = ['f_'+str(i) for i in range(tmp_df.shape[1])]\n",
    "                    tmp_df.rename(columns={'f_75':'Original'}, inplace=True)\n",
    "                    \n",
    "                    tmp_df['Subject'] = subj\n",
    "                    tmp_df['Class'] = 1 if label == '1' else 0\n",
    "                    data = data.append(tmp_df,ignore_index=True)\n",
    "                    #print(data.shape)   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_move_data('6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data[data['Class'] == 1].shape)\n",
    "#print(data[data['Class'] == 0].shape)\n",
    "#data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 28\n",
    "batch_size = 8      # Batch size\n",
    "seq_len = input_width          # Number of steps\n",
    "learning_rate = 0.0001\n",
    "epochs = 30\n",
    "n_classes = 2\n",
    "n_channels = 75\n",
    "num_features = n_channels\n",
    "#actif = tf.nn.tanh ## ok\n",
    "#actif = tf.nn.relu ## ok\n",
    "actif = tf.nn.leaky_relu ## good\n",
    "#actif = tf.sigmoid ## bad\n",
    "\n",
    "#init = tf.contrib.layers.variance_scaling_initializer(factor=1.0, mode='FAN_AVG', uniform=False) ## ok\n",
    "#init = tf.random_normal_initializer() ## bad\n",
    "init = tf.glorot_uniform_initializer() ## good\n",
    "#init = tf.glorot_normal_initializer() ## ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "* Placeholders\n",
    "* Build Convolutional Layers (Note: Should we use a different activation? Like tf.nn.tanh?)\n",
    "* Then flatten and pass to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_down():\n",
    "    tf.reset_default_graph()\n",
    "    graph = tf.Graph()\n",
    "    tf.set_random_seed(random_seed)\n",
    "    # Construct placeholders\n",
    "    with graph.as_default(), tf.device('/gpu:0'):\n",
    "        tf.set_random_seed(random_seed)\n",
    "        inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "        labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "        keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "        learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')\n",
    "        \n",
    "        # (batch, 28, 75) --> (batch, 14, 512)\n",
    "        conv1 = tf.layers.conv1d(inputs=inputs_, filters=512, kernel_size=3, strides=1, \n",
    "                                 padding='same', activation = actif, kernel_initializer=init)\n",
    "        max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "\n",
    "        # (batch, 14, 132) --> (batch, 7, 256)\n",
    "        conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=256, kernel_size=5, strides=1, \n",
    "                                 padding='same', activation = actif, kernel_initializer=init)\n",
    "        max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "\n",
    "        # (batch, 7, 64) --> (batch, 7, 128)\n",
    "        conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=128, kernel_size=7, strides=1, \n",
    "                                 padding='same', activation = actif, kernel_initializer=init)\n",
    "    \n",
    "        flat = tf.reshape(conv3, (-1, 7*128))\n",
    "        dense1 = tf.layers.dense(inputs=flat,   units=256, activation = actif)\n",
    "        dense2 = tf.layers.dense(inputs=dense1, units=128, activation = actif)\n",
    "        dense3 = tf.layers.dense(inputs=dense2, units=64,  activation = actif)\n",
    "        dense4 = tf.layers.dense(inputs=dense3, units=32,  activation = actif)\n",
    "        dense5 = tf.layers.dense(inputs=dense4, units=16,  activation = actif)\n",
    "        dense6 = tf.layers.dense(inputs=dense5, units= 8,  activation = actif)\n",
    "\n",
    "        dropout = tf.nn.dropout(dense6, keep_prob=keep_prob_, seed = random_seed)\n",
    "\n",
    "        # Predictions\n",
    "        logits = tf.layers.dense(dropout, n_classes)\n",
    "    \n",
    "        # Cost function and optimizer\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
    "            labels=labels_))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    " \n",
    "        # Accuracy\n",
    "        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "        return (graph, cost, optimizer,logits, accuracy, inputs_ , labels_ , keep_prob_, learning_rate_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_move(mov):\n",
    "    results = []\n",
    "    appended_data = load_move_data(mov)\n",
    "    print(\"Move:\", mov, \"Data size:\", appended_data.shape)\n",
    "    subjects = list(appended_data['Subject'].unique())\n",
    "    #subjects   = ['s01','s02','s03','s04','s05','s06','s07','s08','s09','s10']\n",
    "    #start_timex = datetime.now()\n",
    "    \n",
    "    for test_subj in subjects:\n",
    "        print('Doing subj:', test_subj)\n",
    "        subj_start_time = datetime.now()\n",
    "        ### Split data into Train and Test\n",
    "        #test_subj           = 's06'\n",
    "        test_subject        = appended_data[appended_data['Subject'] == test_subj]\n",
    "        # test only on original data .. don't include augment data\n",
    "        test_subject = test_subject[test_subject['Original'] == 1]\n",
    "\n",
    "        train_subjects         = appended_data[appended_data['Subject'] != test_subj]\n",
    "        #train_subjects = train_subjects[train_subjects['Class'] == 0]\n",
    "\n",
    "        X_train, labels_train  = preprocess.segment_signal(train_subjects, input_width, num_features)\n",
    "        X_test, labels_test    = preprocess.segment_signal(test_subject, input_width, num_features)\n",
    "\n",
    "        # Normalize?\n",
    "        #X_train, mean_   = zero_mean(X_train,0) \n",
    "        ##X_train, mean_, std_    = standardize(X_train,0,0)\n",
    "        # replace NaNs with 0's\n",
    "        X_train[np.isnan(X_train)] = 0\n",
    "\n",
    "        # Normalize?\n",
    "        #X_test, _        = zero_mean(X_test,mean_, train=False)\n",
    "        ##X_test, _, _            = standardize(X_test,mean_, std_, train=False)\n",
    "        # replace NaNs with 0's\n",
    "        X_test[np.isnan(X_test)] = 0\n",
    "\n",
    "\n",
    "\n",
    "        #X_train, mean, std    = normalize(X_train)\n",
    "        #X_test                = normalize(X_test)\n",
    "\n",
    "        #### One-hot encoding for labels:\n",
    "        # Notice that we add two extra elements 0,1\n",
    "        # Because sometimes we only have correct or incorrect\n",
    "        # move for some subjects and this makes one hot encoding not possible\n",
    "        # one_hot and then drop the elements we added        \n",
    "        y_tr   = preprocess.one_hot(np.append(labels_train, [0,1]))[:-2]\n",
    "        y_test = preprocess.one_hot(np.append(labels_test, [0,1]))[:-2]\n",
    "        #print('Doing', test_subj)\n",
    "        #we make sure there's at least 1 test episode for this test subject\n",
    "        #otherwise no point training the CNN\n",
    "        if len(y_test) > 0:\n",
    "            graph, cost, optimizer, logits, accuracy, inputs_ , labels_ , keep_prob_, learning_rate_ = create_graph_down()\n",
    "            #with graph.as_default():\n",
    "            #    saver = tf.train.Saver()    \n",
    "            with tf.Session(graph=graph) as sess:\n",
    "                saver = tf.train.Saver()    \n",
    "                tf.set_random_seed(random_seed)\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                # Loop over epochs\n",
    "                for e in range(epochs):\n",
    "                    # Loop over batches\n",
    "                    #for x,y in get_random_batches(X_train, y_tr, num_batches = 125, batch_size = 125):\n",
    "                    for x,y in preprocess.get_batches(X_train, y_tr, batch_size, shuffle=True):            \n",
    "                        # Feed dictionary\n",
    "                        feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "\n",
    "                        # Loss\n",
    "                        loss, _ ,logits_, acc = sess.run([cost, optimizer, logits, accuracy], feed_dict = feed) \n",
    "                        #print('Predicted:',tf.argmax(logits_, 1).eval())\n",
    "                        #print('Actual:',tf.argmax(y, 1).eval())\n",
    "                        #print(acc)\n",
    "                        #print('----')\n",
    "\n",
    "                        # Print at each 5 epochs\n",
    "                        #if (e % 50 == 0):\n",
    "                        #    print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                        #          \"Train loss: {:6f}\".format(loss),\n",
    "                        #          \"Train acc: {:.6f}\".format(acc))\n",
    "\n",
    "                # training has finished .. now predict the test set\n",
    "                test_acc = []\n",
    "                print(X_test.shape, y_test.shape)\n",
    "                for x_t, y_t in preprocess.get_batches(X_test, y_test, batch_size=10, shuffle=True):\n",
    "                    #    #print(x_t)\n",
    "                    feed = {inputs_: x_t,\n",
    "                            labels_: y_t,\n",
    "                            keep_prob_: 1}\n",
    "                        #print(x_t.shape)\n",
    "\n",
    "                    batch_acc, b_logits = sess.run([accuracy,logits], feed_dict=feed)\n",
    "                    #print('Predicted:',tf.argmax(b_logits, 1).eval())\n",
    "                    #print('Actual:',tf.argmax(y_t, 1).eval())\n",
    "                    #print(batch_acc)\n",
    "                    #print('----')\n",
    "                    test_acc.append(batch_acc)\n",
    "\n",
    "                results.append(np.mean(test_acc))\n",
    "                    #print(\"Move: \"+mov+\" .. done testing on Subj:\" + test_subj)\n",
    "                    #print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))\n",
    "                    #print(\"Time taken: \", datetime.now() - start_time)\n",
    "                    #print(\"===============================================\")\n",
    "        print(\"Subj:\", test_subj,\"took: \", datetime.now() - subj_start_time)\n",
    "    return results  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = process_move('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move: 0 Data size: (11900, 78)\n",
      "Doing subj: 104\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 104 took:  0:00:09.408696\n",
      "Doing subj: 209\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 209 took:  0:00:08.315073\n",
      "Doing subj: 205\n",
      "(2, 28, 75) (2, 2)\n",
      "Subj: 205 took:  0:00:08.509293\n",
      "Doing subj: 213\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 213 took:  0:00:08.440477\n",
      "Doing subj: 303\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 303 took:  0:00:11.081040\n",
      "Doing subj: 204\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 204 took:  0:00:08.386379\n",
      "Doing subj: 201\n",
      "(13, 28, 75) (13, 2)\n",
      "Subj: 201 took:  0:00:09.853670\n",
      "Doing subj: 206\n",
      "(11, 28, 75) (11, 2)\n",
      "Subj: 206 took:  0:00:08.564911\n",
      "Doing subj: 103\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 103 took:  0:00:08.316638\n",
      "Doing subj: 305\n",
      "(10, 28, 75) (10, 2)\n",
      "Subj: 305 took:  0:00:08.646218\n",
      "Doing subj: 217\n",
      "(8, 28, 75) (8, 2)\n",
      "Subj: 217 took:  0:00:08.317584\n",
      "Doing subj: 105\n",
      "(11, 28, 75) (11, 2)\n",
      "Subj: 105 took:  0:00:08.384270\n",
      "Doing subj: 304\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 304 took:  0:00:08.667765\n",
      "Doing subj: 302\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 302 took:  0:00:08.359027\n",
      "Doing subj: 212\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 212 took:  0:00:08.492486\n",
      "Doing subj: 102\n",
      "(23, 28, 75) (23, 2)\n",
      "Subj: 102 took:  0:00:08.335795\n",
      "Doing subj: 306\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 306 took:  0:00:08.464976\n",
      "Doing subj: 214\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 214 took:  0:00:08.422285\n",
      "Doing subj: 307\n",
      "(11, 28, 75) (11, 2)\n",
      "Subj: 307 took:  0:00:08.409573\n",
      "Doing subj: 215\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 215 took:  0:00:08.555205\n",
      "Doing subj: 301\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 301 took:  0:00:08.417923\n",
      "Doing subj: 101\n",
      "(9, 28, 75) (9, 2)\n",
      "Subj: 101 took:  0:00:08.504457\n",
      "Doing subj: 211\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 211 took:  0:00:08.077889\n",
      "Doing subj: 216\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 216 took:  0:00:08.049948\n",
      "Doing subj: 207\n",
      "(21, 28, 75) (21, 2)\n",
      "Subj: 207 took:  0:00:06.872662\n",
      "Overall accuracy: 0.918810\n",
      "Time taken:  0:03:51.304766\n",
      "===============================================\n",
      "Move: 1 Data size: (12908, 78)\n",
      "Doing subj: 104\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 104 took:  0:00:09.349157\n",
      "Doing subj: 209\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 209 took:  0:00:09.145127\n",
      "Doing subj: 205\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 205 took:  0:00:09.189939\n",
      "Doing subj: 213\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 213 took:  0:00:09.144880\n",
      "Doing subj: 303\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 303 took:  0:00:09.100627\n",
      "Doing subj: 204\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 204 took:  0:00:09.167356\n",
      "Doing subj: 201\n",
      "(14, 28, 75) (14, 2)\n",
      "Subj: 201 took:  0:00:08.400982\n",
      "Doing subj: 210\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 210 took:  0:00:09.301495\n",
      "Doing subj: 211\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 211 took:  0:00:09.207918\n",
      "Doing subj: 206\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 206 took:  0:00:08.426392\n",
      "Doing subj: 103\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 103 took:  0:00:09.282450\n",
      "Doing subj: 305\n",
      "(10, 28, 75) (10, 2)\n",
      "Subj: 305 took:  0:00:09.247116\n",
      "Doing subj: 217\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 217 took:  0:00:08.866608\n",
      "Doing subj: 105\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 105 took:  0:00:09.134071\n",
      "Doing subj: 304\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 304 took:  0:00:09.155379\n",
      "Doing subj: 302\n",
      "(13, 28, 75) (13, 2)\n",
      "Subj: 302 took:  0:00:09.760601\n",
      "Doing subj: 212\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 212 took:  0:00:09.270892\n",
      "Doing subj: 102\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 102 took:  0:00:08.856434\n",
      "Doing subj: 306\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 306 took:  0:00:09.184870\n",
      "Doing subj: 214\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 214 took:  0:00:09.147025\n",
      "Doing subj: 307\n",
      "(13, 28, 75) (13, 2)\n",
      "Subj: 307 took:  0:00:09.175406\n",
      "Doing subj: 216\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 216 took:  0:00:10.046782\n",
      "Doing subj: 207\n",
      "(15, 28, 75) (15, 2)\n",
      "Subj: 207 took:  0:00:07.950759\n",
      "Doing subj: 301\n",
      "(11, 28, 75) (11, 2)\n",
      "Subj: 301 took:  0:00:09.223332\n",
      "Doing subj: 101\n",
      "(13, 28, 75) (13, 2)\n",
      "Subj: 101 took:  0:00:09.178233\n",
      "Doing subj: 215\n",
      "(4, 28, 75) (4, 2)\n",
      "Subj: 215 took:  0:00:08.800221\n",
      "Overall accuracy: 0.742125\n",
      "Time taken:  0:04:15.744367\n",
      "===============================================\n",
      "Move: 2 Data size: (13972, 78)\n",
      "Doing subj: 104\n",
      "(8, 28, 75) (8, 2)\n",
      "Subj: 104 took:  0:00:10.019971\n",
      "Doing subj: 209\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 209 took:  0:00:09.871786\n",
      "Doing subj: 213\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 213 took:  0:00:09.841296\n",
      "Doing subj: 303\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 303 took:  0:00:09.760246\n",
      "Doing subj: 204\n",
      "(58, 28, 75) (58, 2)\n",
      "Subj: 204 took:  0:00:08.574362\n",
      "Doing subj: 201\n",
      "(46, 28, 75) (46, 2)\n",
      "Subj: 201 took:  0:00:08.725919\n",
      "Doing subj: 210\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 210 took:  0:00:09.883846\n",
      "Doing subj: 206\n",
      "(17, 28, 75) (17, 2)\n",
      "Subj: 206 took:  0:00:09.646996\n",
      "Doing subj: 103\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 103 took:  0:00:12.013121\n",
      "Doing subj: 203\n",
      "(29, 28, 75) (29, 2)\n",
      "Subj: 203 took:  0:00:09.160550\n",
      "Doing subj: 305\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 305 took:  0:00:09.992454\n",
      "Doing subj: 217\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 217 took:  0:00:10.688758\n",
      "Doing subj: 105\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 105 took:  0:00:09.868575\n",
      "Doing subj: 304\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 304 took:  0:00:09.933146\n",
      "Doing subj: 302\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 302 took:  0:00:09.886261\n",
      "Doing subj: 212\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 212 took:  0:00:10.493644\n",
      "Doing subj: 102\n",
      "(25, 28, 75) (25, 2)\n",
      "Subj: 102 took:  0:00:09.813157\n",
      "Doing subj: 306\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 306 took:  0:00:10.013495\n",
      "Doing subj: 214\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 214 took:  0:00:09.906287\n",
      "Doing subj: 307\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 307 took:  0:00:09.984332\n",
      "Doing subj: 215\n",
      "(10, 28, 75) (10, 2)\n",
      "Subj: 215 took:  0:00:09.759541\n",
      "Doing subj: 301\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 301 took:  0:00:10.413679\n",
      "Doing subj: 101\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 101 took:  0:00:09.989035\n",
      "Doing subj: 211\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 211 took:  0:00:09.858351\n",
      "Doing subj: 216\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 216 took:  0:00:09.853018\n",
      "Overall accuracy: 0.870800\n",
      "Time taken:  0:04:29.010746\n",
      "===============================================\n",
      "Move: 3 Data size: (14756, 78)\n",
      "Doing subj: 104\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 104 took:  0:00:10.787125\n",
      "Doing subj: 209\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 209 took:  0:00:10.552969\n",
      "Doing subj: 303\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 303 took:  0:00:10.328281\n",
      "Doing subj: 204\n",
      "(58, 28, 75) (58, 2)\n",
      "Subj: 204 took:  0:00:08.309497\n",
      "Doing subj: 201\n",
      "(17, 28, 75) (17, 2)\n",
      "Subj: 201 took:  0:00:09.725040\n",
      "Doing subj: 210\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 210 took:  0:00:10.599306\n",
      "Doing subj: 211\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 211 took:  0:00:10.441870\n",
      "Doing subj: 103\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 103 took:  0:00:10.441281\n",
      "Doing subj: 203\n",
      "(4, 28, 75) (4, 2)\n",
      "Subj: 203 took:  0:00:10.504902\n",
      "Doing subj: 305\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 305 took:  0:00:10.505816\n",
      "Doing subj: 217\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 217 took:  0:00:10.356145\n",
      "Doing subj: 105\n",
      "(14, 28, 75) (14, 2)\n",
      "Subj: 105 took:  0:00:11.000915\n",
      "Doing subj: 304\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 304 took:  0:00:10.460925\n",
      "Doing subj: 302\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 302 took:  0:00:10.346592\n",
      "Doing subj: 212\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 212 took:  0:00:10.514963\n",
      "Doing subj: 102\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 102 took:  0:00:10.214197\n",
      "Doing subj: 306\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 306 took:  0:00:10.467098\n",
      "Doing subj: 214\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 214 took:  0:00:10.449876\n",
      "Doing subj: 307\n",
      "(11, 28, 75) (11, 2)\n",
      "Subj: 307 took:  0:00:10.389659\n",
      "Doing subj: 216\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 216 took:  0:00:10.678635\n",
      "Doing subj: 215\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 215 took:  0:00:10.469584\n",
      "Doing subj: 301\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 301 took:  0:00:10.393698\n",
      "Doing subj: 101\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 101 took:  0:00:10.435597\n",
      "Doing subj: 213\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 213 took:  0:00:10.815504\n",
      "Doing subj: 206\n",
      "(17, 28, 75) (17, 2)\n",
      "Subj: 206 took:  0:00:09.733645\n",
      "Doing subj: 202\n",
      "(1, 28, 75) (1, 2)\n",
      "Subj: 202 took:  0:00:10.544240\n",
      "Doing subj: 207\n",
      "(16, 28, 75) (16, 2)\n",
      "Subj: 207 took:  0:00:09.666984\n",
      "Overall accuracy: 0.913598\n",
      "Time taken:  0:05:01.132384\n",
      "===============================================\n",
      "Move: 4 Data size: (13664, 78)\n",
      "Doing subj: 104\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 104 took:  0:00:10.376569\n",
      "Doing subj: 213\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 213 took:  0:00:09.602211\n",
      "Doing subj: 303\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 303 took:  0:00:09.896112\n",
      "Doing subj: 204\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 204 took:  0:00:09.562807\n",
      "Doing subj: 210\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 210 took:  0:00:09.718859\n",
      "Doing subj: 206\n",
      "(13, 28, 75) (13, 2)\n",
      "Subj: 206 took:  0:00:09.406493\n",
      "Doing subj: 103\n",
      "(25, 28, 75) (25, 2)\n",
      "Subj: 103 took:  0:00:09.450085\n",
      "Doing subj: 305\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 305 took:  0:00:09.575292\n",
      "Doing subj: 202\n",
      "(36, 28, 75) (36, 2)\n",
      "Subj: 202 took:  0:00:08.560715\n",
      "Doing subj: 217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 28, 75) (6, 2)\n",
      "Subj: 217 took:  0:00:09.689421\n",
      "Doing subj: 105\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 105 took:  0:00:09.837023\n",
      "Doing subj: 304\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 304 took:  0:00:09.894053\n",
      "Doing subj: 302\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 302 took:  0:00:09.644537\n",
      "Doing subj: 212\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 212 took:  0:00:09.839561\n",
      "Doing subj: 102\n",
      "(25, 28, 75) (25, 2)\n",
      "Subj: 102 took:  0:00:09.419905\n",
      "Doing subj: 306\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 306 took:  0:00:09.857192\n",
      "Doing subj: 214\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 214 took:  0:00:09.850059\n",
      "Doing subj: 307\n",
      "(13, 28, 75) (13, 2)\n",
      "Subj: 307 took:  0:00:09.653646\n",
      "Doing subj: 215\n",
      "(10, 28, 75) (10, 2)\n",
      "Subj: 215 took:  0:00:09.313848\n",
      "Doing subj: 301\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 301 took:  0:00:09.920963\n",
      "Doing subj: 101\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 101 took:  0:00:09.561091\n",
      "Doing subj: 201\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 201 took:  0:00:08.972299\n",
      "Doing subj: 211\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 211 took:  0:00:09.267808\n",
      "Doing subj: 216\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 216 took:  0:00:08.984891\n",
      "Overall accuracy: 0.819841\n",
      "Time taken:  0:04:09.964134\n",
      "===============================================\n",
      "Move: 5 Data size: (12516, 78)\n",
      "Doing subj: 104\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 104 took:  0:00:09.336675\n",
      "Doing subj: 209\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 209 took:  0:00:08.879443\n",
      "Doing subj: 205\n",
      "(1, 28, 75) (1, 2)\n",
      "Subj: 205 took:  0:00:08.906103\n",
      "Doing subj: 213\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 213 took:  0:00:08.749253\n",
      "Doing subj: 303\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 303 took:  0:00:08.858785\n",
      "Doing subj: 204\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 204 took:  0:00:09.221294\n",
      "Doing subj: 210\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 210 took:  0:00:08.787153\n",
      "Doing subj: 211\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 211 took:  0:00:09.071672\n",
      "Doing subj: 103\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 103 took:  0:00:08.858154\n",
      "Doing subj: 203\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 203 took:  0:00:08.424034\n",
      "Doing subj: 305\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 305 took:  0:00:08.830153\n",
      "Doing subj: 217\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 217 took:  0:00:09.027034\n",
      "Doing subj: 105\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 105 took:  0:00:08.842208\n",
      "Doing subj: 304\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 304 took:  0:00:08.891275\n",
      "Doing subj: 302\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 302 took:  0:00:08.863592\n",
      "Doing subj: 212\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 212 took:  0:00:08.665260\n",
      "Doing subj: 102\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 102 took:  0:00:08.635434\n",
      "Doing subj: 306\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 306 took:  0:00:09.085938\n",
      "Doing subj: 214\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 214 took:  0:00:09.064470\n",
      "Doing subj: 307\n",
      "(11, 28, 75) (11, 2)\n",
      "Subj: 307 took:  0:00:08.879136\n",
      "Doing subj: 216\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 216 took:  0:00:08.984798\n",
      "Doing subj: 215\n",
      "(9, 28, 75) (9, 2)\n",
      "Subj: 215 took:  0:00:08.774602\n",
      "Doing subj: 301\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 301 took:  0:00:09.005877\n",
      "Doing subj: 101\n",
      "(13, 28, 75) (13, 2)\n",
      "Subj: 101 took:  0:00:08.657485\n",
      "Doing subj: 201\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 201 took:  0:00:08.305995\n",
      "Doing subj: 206\n",
      "(20, 28, 75) (20, 2)\n",
      "Subj: 206 took:  0:00:06.739124\n",
      "Overall accuracy: 0.874542\n",
      "Time taken:  0:04:06.747724\n",
      "===============================================\n",
      "Move: 6 Data size: (12964, 78)\n",
      "Doing subj: 104\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 104 took:  0:00:09.449435\n",
      "Doing subj: 209\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 209 took:  0:00:09.192383\n",
      "Doing subj: 213\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 213 took:  0:00:09.216037\n",
      "Doing subj: 303\n",
      "(11, 28, 75) (11, 2)\n",
      "Subj: 303 took:  0:00:09.197810\n",
      "Doing subj: 204\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 204 took:  0:00:09.219992\n",
      "Doing subj: 211\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 211 took:  0:00:09.500129\n",
      "Doing subj: 206\n",
      "(14, 28, 75) (14, 2)\n",
      "Subj: 206 took:  0:00:08.710731\n",
      "Doing subj: 103\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 103 took:  0:00:08.938591\n",
      "Doing subj: 305\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 305 took:  0:00:09.187266\n",
      "Doing subj: 217\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 217 took:  0:00:09.882425\n",
      "Doing subj: 105\n",
      "(16, 28, 75) (16, 2)\n",
      "Subj: 105 took:  0:00:09.295938\n",
      "Doing subj: 304\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 304 took:  0:00:09.249782\n",
      "Doing subj: 302\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 302 took:  0:00:09.124427\n",
      "Doing subj: 212\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 212 took:  0:00:08.863305\n",
      "Doing subj: 102\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 102 took:  0:00:09.000210\n",
      "Doing subj: 306\n",
      "(13, 28, 75) (13, 2)\n",
      "Subj: 306 took:  0:00:09.302368\n",
      "Doing subj: 214\n",
      "(4, 28, 75) (4, 2)\n",
      "Subj: 214 took:  0:00:09.169462\n",
      "Doing subj: 307\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 307 took:  0:00:09.359940\n",
      "Doing subj: 216\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 216 took:  0:00:09.220823\n",
      "Doing subj: 215\n",
      "(9, 28, 75) (9, 2)\n",
      "Subj: 215 took:  0:00:09.142747\n",
      "Doing subj: 301\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 301 took:  0:00:10.261776\n",
      "Doing subj: 101\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 101 took:  0:00:09.173210\n",
      "Doing subj: 201\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 201 took:  0:00:08.728126\n",
      "Doing subj: 210\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 210 took:  0:00:09.349109\n",
      "Doing subj: 207\n",
      "(20, 28, 75) (20, 2)\n",
      "Subj: 207 took:  0:00:07.105917\n",
      "Overall accuracy: 0.865556\n",
      "Time taken:  0:04:07.884359\n",
      "===============================================\n",
      "Move: 7 Data size: (14056, 78)\n",
      "Doing subj: 104\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 104 took:  0:00:10.231771\n",
      "Doing subj: 213\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 213 took:  0:00:10.004431\n",
      "Doing subj: 303\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 303 took:  0:00:09.883623\n",
      "Doing subj: 204\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 204 took:  0:00:09.855603\n",
      "Doing subj: 211\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 211 took:  0:00:09.667511\n",
      "Doing subj: 206\n",
      "(25, 28, 75) (25, 2)\n",
      "Subj: 206 took:  0:00:09.221369\n",
      "Doing subj: 103\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 103 took:  0:00:09.731221\n",
      "Doing subj: 305\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 305 took:  0:00:09.885922\n",
      "Doing subj: 202\n",
      "(23, 28, 75) (23, 2)\n",
      "Subj: 202 took:  0:00:09.530759\n",
      "Doing subj: 217\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 217 took:  0:00:10.100318\n",
      "Doing subj: 105\n",
      "(13, 28, 75) (13, 2)\n",
      "Subj: 105 took:  0:00:09.946168\n",
      "Doing subj: 304\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 304 took:  0:00:10.016857\n",
      "Doing subj: 302\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 302 took:  0:00:09.876315\n",
      "Doing subj: 102\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 102 took:  0:00:09.805376\n",
      "Doing subj: 306\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 306 took:  0:00:10.205261\n",
      "Doing subj: 214\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 214 took:  0:00:10.030379\n",
      "Doing subj: 307\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 307 took:  0:00:09.968105\n",
      "Doing subj: 216\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 216 took:  0:00:10.054476\n",
      "Doing subj: 215\n",
      "(8, 28, 75) (8, 2)\n",
      "Subj: 215 took:  0:00:09.952618\n",
      "Doing subj: 207\n",
      "(9, 28, 75) (9, 2)\n",
      "Subj: 207 took:  0:00:08.894638\n",
      "Doing subj: 301\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 301 took:  0:00:09.967754\n",
      "Doing subj: 101\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 101 took:  0:00:11.625660\n",
      "Doing subj: 209\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 209 took:  0:00:09.180491\n",
      "Doing subj: 212\n",
      "(5, 28, 75) (5, 2)\n",
      "Subj: 212 took:  0:00:09.217921\n",
      "Overall accuracy: 0.825265\n",
      "Time taken:  0:04:17.245029\n",
      "===============================================\n",
      "Move: 8 Data size: (13832, 78)\n",
      "Doing subj: 104\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 104 took:  0:00:09.994159\n",
      "Doing subj: 209\n",
      "(4, 28, 75) (4, 2)\n",
      "Subj: 209 took:  0:00:09.965631\n",
      "Doing subj: 213\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 213 took:  0:00:09.405114\n",
      "Doing subj: 303\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 303 took:  0:00:09.944971\n",
      "Doing subj: 204\n",
      "(13, 28, 75) (13, 2)\n",
      "Subj: 204 took:  0:00:08.923344\n",
      "Doing subj: 211\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 211 took:  0:00:09.853746\n",
      "Doing subj: 206\n",
      "(10, 28, 75) (10, 2)\n",
      "Subj: 206 took:  0:00:09.543177\n",
      "Doing subj: 103\n",
      "(25, 28, 75) (25, 2)\n",
      "Subj: 103 took:  0:00:09.649887\n",
      "Doing subj: 305\n",
      "(11, 28, 75) (11, 2)\n",
      "Subj: 305 took:  0:00:09.879361\n",
      "Doing subj: 202\n",
      "(47, 28, 75) (47, 2)\n",
      "Subj: 202 took:  0:00:09.142510\n",
      "Doing subj: 217\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 217 took:  0:00:10.066409\n",
      "Doing subj: 105\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 105 took:  0:00:09.860410\n",
      "Doing subj: 304\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 304 took:  0:00:09.833396\n",
      "Doing subj: 302\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 302 took:  0:00:09.916674\n",
      "Doing subj: 102\n",
      "(24, 28, 75) (24, 2)\n",
      "Subj: 102 took:  0:00:09.672333\n",
      "Doing subj: 306\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 306 took:  0:00:09.740239\n",
      "Doing subj: 214\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 214 took:  0:00:09.761994\n",
      "Doing subj: 307\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 307 took:  0:00:09.931969\n",
      "Doing subj: 216\n",
      "(6, 28, 75) (6, 2)\n",
      "Subj: 216 took:  0:00:09.836116\n",
      "Doing subj: 215\n",
      "(10, 28, 75) (10, 2)\n",
      "Subj: 215 took:  0:00:09.922291\n",
      "Doing subj: 207\n",
      "(7, 28, 75) (7, 2)\n",
      "Subj: 207 took:  0:00:09.031394\n",
      "Doing subj: 301\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 301 took:  0:00:09.770534\n",
      "Doing subj: 101\n",
      "(12, 28, 75) (12, 2)\n",
      "Subj: 101 took:  0:00:09.951476\n",
      "Doing subj: 212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 28, 75) (6, 2)\n",
      "Subj: 212 took:  0:00:08.943458\n",
      "Overall accuracy: 0.841220\n",
      "Time taken:  0:04:12.685287\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "moves = ['0','1','2','3','4','5','6','7','8']\n",
    "results_dict = {}\n",
    "for mov in moves:\n",
    "    start_time  = datetime.now()\n",
    "    mov_results = process_move(mov)\n",
    "    results_dict[mov] = mov_results\n",
    "    print(\"Overall accuracy: {:.6f}\".format(np.mean(results_dict[mov])))\n",
    "    print(\"Time taken: \", datetime.now() - start_time)\n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': [1.0,\n",
       "  0.85714287,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.85714287,\n",
       "  0.8,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9,\n",
       "  0.8333333,\n",
       "  0.95,\n",
       "  0.8,\n",
       "  0.71428573,\n",
       "  0.9,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.8,\n",
       "  0.8333333,\n",
       "  0.85],\n",
       " '1': [0.85714287,\n",
       "  0.8333333,\n",
       "  0.6,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0.6666667,\n",
       "  0.7,\n",
       "  0.8333333,\n",
       "  1.0,\n",
       "  0.6,\n",
       "  1.0,\n",
       "  0.8,\n",
       "  0.5714286,\n",
       "  0.8,\n",
       "  0.5,\n",
       "  0.9,\n",
       "  0.8333333,\n",
       "  1.0,\n",
       "  0.8,\n",
       "  0.5,\n",
       "  0.9,\n",
       "  1.0,\n",
       "  0.3,\n",
       "  1.0,\n",
       "  0.8,\n",
       "  0.0],\n",
       " '2': [1.0,\n",
       "  1.0,\n",
       "  0.8333333,\n",
       "  1.0,\n",
       "  0.82,\n",
       "  0.9,\n",
       "  0.6,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.6666667,\n",
       "  0.95,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0.9,\n",
       "  0.8,\n",
       "  0.9,\n",
       "  1.0,\n",
       "  0.4,\n",
       "  0.6],\n",
       " '3': [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.85999995,\n",
       "  0.9,\n",
       "  0.6,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.75,\n",
       "  0.8333333,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.6666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.4,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.85714287,\n",
       "  0.9,\n",
       "  1.0,\n",
       "  0.9],\n",
       " '4': [0.6666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.42857143,\n",
       "  1.0,\n",
       "  0.4,\n",
       "  0.95,\n",
       "  1.0,\n",
       "  0.4333333,\n",
       "  0.8333333,\n",
       "  1.0,\n",
       "  0.85714287,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0.95,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.6,\n",
       "  0.9,\n",
       "  0.9,\n",
       "  1.0,\n",
       "  0.4,\n",
       "  0.85714287],\n",
       " '5': [1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.6666667,\n",
       "  0.9,\n",
       "  0.5714286,\n",
       "  0.8333333,\n",
       "  1.0,\n",
       "  0.95,\n",
       "  0.8,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9,\n",
       "  1.0,\n",
       "  0.9,\n",
       "  0.6666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.8,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.75],\n",
       " '6': [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0.7,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.2,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.8888889,\n",
       "  0.8,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.65],\n",
       " '7': [1.0,\n",
       "  1.0,\n",
       "  0.9,\n",
       "  1.0,\n",
       "  0.5714286,\n",
       "  0.85,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.79999995,\n",
       "  0.85714287,\n",
       "  1.0,\n",
       "  0.8333333,\n",
       "  0.9,\n",
       "  0.95,\n",
       "  1.0,\n",
       "  0.8333333,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0.11111111,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0.2],\n",
       " '8': [1.0,\n",
       "  0.75,\n",
       "  0.33333334,\n",
       "  1.0,\n",
       "  0.9,\n",
       "  0.8333333,\n",
       "  0.6,\n",
       "  1.0,\n",
       "  0.9,\n",
       "  0.775,\n",
       "  0.8333333,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.7,\n",
       "  0.95,\n",
       "  1.0,\n",
       "  0.42857143,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9,\n",
       "  0.2857143,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-78f38b201aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "np.mean(results_dict['3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {'0': [1.0, 0.85714287, 1.0, 1.0, 1.0, 0.85714287, 0.8, 1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 0.9, 0.8333333, 0.95, 0.8, 0.71428573, 0.9, 1.0, 1.0, 1.0, 0.8, 0.8333333, 0.85], '1': [0.85714287, 0.8333333, 0.6, 0.5, 1.0, 0.6666667, 0.7, 0.8333333, 1.0, 0.6, 1.0, 0.8, 0.5714286, 0.8, 0.5, 0.9, 0.8333333, 1.0, 0.8, 0.5, 0.9, 1.0, 0.3, 1.0, 0.8, 0.0], '2': [1.0, 1.0, 0.8333333, 1.0, 0.82, 0.9, 0.6, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666667, 0.95, 1.0, 0.5, 0.9, 0.8, 0.9, 1.0, 0.4, 0.6], '3': [1.0, 1.0, 1.0, 0.85999995, 0.9, 0.6, 1.0, 1.0, 0.75, 0.8333333, 1.0, 1.0, 1.0, 1.0, 0.6666667, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85714287, 0.9, 1.0, 0.9], '4': [0.6666667, 1.0, 1.0, 0.42857143, 1.0, 0.4, 0.95, 1.0, 0.4333333, 0.8333333, 1.0, 0.85714287, 1.0, 0.5, 0.95, 1.0, 1.0, 1.0, 0.6, 0.9, 0.9, 1.0, 0.4, 0.85714287], '5': [1.0, 1.0, 0.0, 0.6666667, 0.9, 0.5714286, 0.8333333, 1.0, 0.95, 0.8, 1.0, 1.0, 0.9, 1.0, 0.9, 0.6666667, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75], '6': [1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.7, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8888889, 0.8, 1.0, 1.0, 0.0, 0.65], '7': [1.0, 1.0, 0.9, 1.0, 0.5714286, 0.85, 1.0, 1.0, 0.79999995, 0.85714287, 1.0, 0.8333333, 0.9, 0.95, 1.0, 0.8333333, 1.0, 0.5, 1.0, 0.11111111, 1.0, 1.0, 0.5, 0.2], '8': [1.0, 0.75, 0.33333334, 1.0, 0.9, 0.8333333, 0.6, 1.0, 0.9, 0.775, 0.8333333, 1.0, 1.0, 0.7, 0.95, 1.0, 0.42857143, 1.0, 1.0, 0.9, 0.2857143, 1.0, 1.0, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('NIPS19-Perkeso-CNN-Results.json', 'w') as outfile:\n",
    "    json.dump(str(results_dict), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('NIPS19-Perkeso-CNN-Results.json') as json_file:  \n",
    "    results_dict = json.loads(json_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D = {}\n",
    "for key, value in results_dict.items():\n",
    "    D[key] = (np.mean(value)*100)\n",
    "\n",
    "\n",
    "# Create bars\n",
    "barWidth = 1\n",
    "bars1 = list(D.values())\n",
    "\n",
    "# The X position of bars\n",
    "r1 = range(len(D))\n",
    "\n",
    "plt.bar(r1, bars1, align='center', color = (0.2,0.7,0.9,0.6))\n",
    "\n",
    "plt.xticks(range(len(D)), list(D.keys()))\n",
    "\n",
    "\n",
    "plt.xlabel('Gesture',  fontsize=18)\n",
    "plt.ylabel('Accuracy %', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.24172980017569"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(D.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 91.88095228,\n",
       " '1': 74.21245411538462,\n",
       " '2': 87.08000000000001,\n",
       " '3': 91.35978822222222,\n",
       " '4': 81.98412695833332,\n",
       " '5': 87.45421269230769,\n",
       " '6': 86.55555559999999,\n",
       " '7': 82.52645470833335,\n",
       " '8': 84.122023625}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71428573 1.0\n"
     ]
    }
   ],
   "source": [
    "print(min(results_dict['0']), max(results_dict['0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3, 4, 1, 4, 1].count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['6'].count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "12\n",
      "0.71428573 1.0\n",
      "----\n",
      "1\n",
      "6\n",
      "0.0 1.0\n",
      "----\n",
      "2\n",
      "12\n",
      "0.4 1.0\n",
      "----\n",
      "3\n",
      "17\n",
      "0.4 1.0\n",
      "----\n",
      "4\n",
      "10\n",
      "0.4 1.0\n",
      "----\n",
      "5\n",
      "14\n",
      "0.0 1.0\n",
      "----\n",
      "6\n",
      "17\n",
      "0.0 1.0\n",
      "----\n",
      "7\n",
      "11\n",
      "0.11111111 1.0\n",
      "----\n",
      "8\n",
      "11\n",
      "0.2857143 1.0\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "moves = ['0','1','2','3','4','5','6','7','8']\n",
    "for m in moves:\n",
    "    print(m)\n",
    "    print(results_dict[m].count(1))\n",
    "    print(min(results_dict[m]), max(results_dict[m]))\n",
    "    print('----')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
